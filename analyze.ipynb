{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import os\n",
    "from datetime import datetime\n",
    "import mne\n",
    "from mne.preprocessing import ICA\n",
    "from scipy import signal\n",
    "import warnings\n",
    "import traceback\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "log_path = \"data_logs/Aws Safi\"\n",
    "data_path = \"data\"\n",
    "\n",
    "results_dir = \"results\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(\"data\"):\n",
    "    if file.endswith(\"csv\"):\n",
    "        with open(f\"data/{file}\", 'r') as f:\n",
    "            l = f.readlines()\n",
    "            if not l[0].startswith('Timestamp') and l[1].startswith('Timestamp'):\n",
    "                l = l[1:]\n",
    "        with open(f\"data/{file}\", 'w') as f:\n",
    "            f.writelines(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully parsed 3 log files\n"
     ]
    }
   ],
   "source": [
    "def add_three_hours(timestamp):\n",
    "    k = timestamp.split('T')\n",
    "    k[1]= str(int(k[1][:2])+3)+k[1][2:]\n",
    "    return 'T'.join(k)\n",
    "def mp(c):\n",
    "    \"\"\"Convert log color markers to valid Plotly colors\"\"\"\n",
    "    if c.strip()==\"'blue'\":\n",
    "        return 'blue'\n",
    "    if c.strip()==\"'lightblue'\":\n",
    "        return 'red'\n",
    "    return 'black'\n",
    "\n",
    "logs = {}\n",
    "for log_file in os.listdir(log_path):\n",
    "    if not log_file.endswith('.txt'):\n",
    "        continue\n",
    "    identifier = log_file.split(\"_run\")[1].split(\".\")[0]\n",
    "    try:\n",
    "        with open(f\"{log_path}/{log_file}\", \"r\") as f:\n",
    "            a = f.readlines()\n",
    "            if not a:\n",
    "                print(f\"WARNING: Empty log file: {log_file}\")\n",
    "                continue\n",
    "            logs[identifier] = [\n",
    "                (datetime.strptime(add_three_hours(line.split(\" \")[0]), \"[%Y-%m-%dT%H:%M:%S.%fZ]\").timestamp(),\n",
    "                 mp(line.split(\" \")[-1]),\n",
    "                 \" \".join(line.split(\" \")[2:]))\n",
    "                for line in a\n",
    "                if 'blue' in line or '+' in line\n",
    "            ]\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR parsing log file {log_file}: {str(e)}\")\n",
    "\n",
    "print(f\"Successfully parsed {len(logs)} log files\")\n",
    "\n",
    "def validate_csv(file_path):\n",
    "    \"\"\"Validate if a CSV file is readable and has data\"\"\"\n",
    "    try:\n",
    "        if not os.path.exists(file_path):\n",
    "            return False, \"File does not exist\"\n",
    "\n",
    "        if os.path.getsize(file_path) == 0:\n",
    "            return False, \"File is empty\"\n",
    "\n",
    "        with open(file_path, 'r') as f:\n",
    "            first_lines = []\n",
    "            for i, line in enumerate(f):\n",
    "                if i >= 5:\n",
    "                    break\n",
    "                first_lines.append(line)\n",
    "\n",
    "            if not first_lines:\n",
    "                return False, \"File has no content\"\n",
    "\n",
    "            if not ',' in first_lines[0]:\n",
    "                return False, \"File does not appear to be a valid CSV\"\n",
    "        try:\n",
    "            df_sample = pd.read_csv(file_path, nrows=5)\n",
    "            if df_sample.empty:\n",
    "                return False, \"Pandas could not read any rows\"\n",
    "            return True, \"Valid\"\n",
    "        except pd.errors.EmptyDataError:\n",
    "            return False, \"No columns to parse from file\"\n",
    "        except pd.errors.ParserError:\n",
    "            return False, \"Parser error - file may be corrupted\"\n",
    "        except Exception as e:\n",
    "            return False, f\"Error reading with pandas: {str(e)}\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return False, f\"Validation error: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_eeg(file_path, identifier, logs):\n",
    "    \"\"\"Process EEG data and print findings\"\"\"\n",
    "    print(f\"\\n{'='*80}\\nProcessing file: {os.path.basename(file_path)}\\n{'='*80}\")\n",
    "\n",
    "    try:\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            print(f\"Successfully read data: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR: Could not read data: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "        if df.empty:\n",
    "            print(\"ERROR: DataFrame is empty\")\n",
    "            return None\n",
    "\n",
    "        if 'Timestamp' in df.columns:\n",
    "            df.set_index('Timestamp', inplace=True)\n",
    "            print(\"Set 'Timestamp' as index\")\n",
    "\n",
    "        eeg_channels = [col for col in df.columns if col.startswith('EEG.') and\n",
    "                       not any(x in col for x in ['Counter', 'Interpolated', 'RawCq', 'Battery', 'MarkerHardware'])]\n",
    "\n",
    "        if not eeg_channels:\n",
    "            print(\"ERROR: No EEG channels found in data\")\n",
    "            return None\n",
    "\n",
    "        print(f\"Found {len(eeg_channels)} EEG channels: {', '.join(eeg_channels)}\")\n",
    "\n",
    "        cq_columns = [col for col in df.columns if col.startswith('CQ.') and col != 'CQ.Overall']\n",
    "        if cq_columns:\n",
    "            cq_stats = df[cq_columns].describe()\n",
    "            poor_quality_mask = (df[cq_columns] < 2).any(axis=1)\n",
    "            poor_quality_pct = (poor_quality_mask.sum() / len(df)) * 100\n",
    "            print(f\"Signal quality analysis:\")\n",
    "            print(f\"  - Poor quality samples: {poor_quality_mask.sum()} ({poor_quality_pct:.2f}%)\")\n",
    "\n",
    "            channel_quality = {}\n",
    "            for col in cq_columns:\n",
    "                ch_name = col.replace('CQ.', '')\n",
    "                poor_ch = (df[col] < 2).sum()\n",
    "                poor_ch_pct = (poor_ch / len(df)) * 100\n",
    "                channel_quality[ch_name] = (poor_ch_pct, df[col].mean())\n",
    "\n",
    "            print(\"  - Channels with poorest quality:\")\n",
    "            worst_channels = sorted(channel_quality.items(), key=lambda x: x[1][0], reverse=True)[:3]\n",
    "            for ch, (pct, mean_q) in worst_channels:\n",
    "                print(f\"    * {ch}: {pct:.2f}% poor quality, avg quality: {mean_q:.2f}\")\n",
    "\n",
    "        data = df[eeg_channels].values.T\n",
    "\n",
    "        ch_names = [ch.replace('EEG.', '') for ch in eeg_channels]\n",
    "\n",
    "        if 'OriginalTimestamp' in df.columns:\n",
    "            timestamps = df['OriginalTimestamp'].values\n",
    "            sfreq = 1.0 / np.median(np.diff(timestamps))\n",
    "        else:\n",
    "            sfreq = 128.0\n",
    "\n",
    "        print(f\"Sampling frequency: {sfreq:.2f} Hz\")\n",
    "\n",
    "        info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types='eeg')\n",
    "        raw = mne.io.RawArray(data, info)\n",
    "\n",
    "        try:\n",
    "            montage = mne.channels.make_standard_montage('standard_1020')\n",
    "            raw.set_montage(montage, match_case=False)\n",
    "            print(\"Successfully set 10-20 montage\")\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not set montage: {str(e)}\")\n",
    "\n",
    "        print(\"\\nApplying preprocessing steps:\")\n",
    "        raw_filtered = raw.copy().filter(l_freq=0.5, h_freq=64)\n",
    "        print(\"  - Applied band-pass filter (1-40 Hz)\")\n",
    "\n",
    "        raw_notch = raw_filtered.copy().notch_filter(freqs=[50, 60])\n",
    "        print(\"  - Applied notch filter (50/60 Hz)\")\n",
    "\n",
    "        print(\"\\nSpectral analysis:\")\n",
    "        bands = {\n",
    "            'delta': (0.5, 4),\n",
    "            'theta': (4, 8),\n",
    "            'alpha': (8, 12),\n",
    "            'beta': (12, 30),\n",
    "            'gamma': (30, 64) # no max\n",
    "        }\n",
    "\n",
    "        band_powers = {}\n",
    "        for band_name, (fmin, fmax) in bands.items():\n",
    "            psd = raw_notch.compute_psd(method=\"welch\", fmin=fmin, fmax=fmax,\n",
    "                                      n_fft=int(sfreq * 2), n_overlap=int(sfreq))\n",
    "            print(\"psd:\", psd)\n",
    "            print(\"psd type:\", type(psd))\n",
    "            #Is psd a number or a time series? we want both\n",
    "\n",
    "            psds_data = psd.get_data()\n",
    "            freqs = psd.freqs\n",
    "\n",
    "            band_powers[band_name] = np.mean(psds_data, axis=1)\n",
    "\n",
    "        total_power = sum(np.mean(powers) for powers in band_powers.values())\n",
    "        for band, powers in band_powers.items():\n",
    "            rel_power = np.mean(powers) / total_power * 100\n",
    "            print(f\"  - {band.capitalize()} power: {rel_power:.2f}%\")\n",
    "\n",
    "        dominant_band = max(band_powers.items(), key=lambda x: np.mean(x[1]))\n",
    "        print(f\"  - Dominant frequency band: {dominant_band[0].capitalize()}\")\n",
    "\n",
    "        print(\"\\nRunning ICA for artifact removal:\")\n",
    "        ica = ICA(n_components=min(15, len(ch_names)), random_state=42)\n",
    "        ica.fit(raw_notch)\n",
    "\n",
    "        try:\n",
    "            eog_indices, eog_scores = ica.find_bads_eog(raw_notch)\n",
    "            if eog_indices:\n",
    "                ica.exclude = eog_indices\n",
    "                print(f\"  - Identified {len(eog_indices)} components related to eye artifacts\")\n",
    "        except Exception as e:\n",
    "            print(f\"  - Could not automatically identify eye artifacts: {str(e)}\")\n",
    "\n",
    "        raw_ica = raw_notch.copy()\n",
    "        ica.apply(raw_ica)\n",
    "        print(\"  - Successfully applied ICA correction\")\n",
    "\n",
    "        if identifier in logs and logs[identifier]:\n",
    "            # print(f\"\\nEvent analysis for recording {identifier}:\")\n",
    "            first_timestamp = df['OriginalTimestamp'].iloc[0] if 'OriginalTimestamp' in df.columns else df.index[0]\n",
    "            event_types = {}\n",
    "            for timestamp, color, description in logs[identifier]:\n",
    "                event_type = None\n",
    "                if '+' in description:\n",
    "                    event_type = 'cross'\n",
    "                elif 'first word' in description.lower() and color == 'r':\n",
    "                    event_type = 'first_word_light'\n",
    "                elif 'first word' in description.lower() and color == 'b':\n",
    "                    event_type = 'first_word_dark'\n",
    "                elif 'second word' in description.lower() and color == 'r':\n",
    "                    event_type = 'second_word_light'\n",
    "                elif 'second word' in description.lower() and color == 'b':\n",
    "                    event_type = 'second_word_dark'\n",
    "\n",
    "                if event_type:\n",
    "                    event_types[event_type] = event_types.get(event_type, 0) + 1\n",
    "\n",
    "            for event_type, count in event_types.items():\n",
    "                print(f\"  - {event_type}: {count} occurrences\")\n",
    "\n",
    "            words = set()\n",
    "            for _, _, description in logs[identifier]:\n",
    "                if \"word '\" in description.lower():\n",
    "                    parts = description.split(\"'\")\n",
    "                    if len(parts) >= 2:\n",
    "                        word = parts[1].strip()\n",
    "                        words.add(word)\n",
    "\n",
    "            if words:\n",
    "                print(f\"  - Unique words presented: {', '.join(words)}\")\n",
    "        else:\n",
    "            print(f\"\\nNo event logs found for recording {identifier}\")\n",
    "\n",
    "        print(\"\\nGenerating visualization...\")\n",
    "\n",
    "        data_clean = raw_ica.get_data()\n",
    "        times = raw_ica.times\n",
    "\n",
    "        fig = go.Figure()\n",
    "\n",
    "        channels_to_plot = min(5, len(ch_names))\n",
    "        channel_indices = np.linspace(0, len(ch_names)-1, channels_to_plot).astype(int)\n",
    "\n",
    "        for i in channel_indices:\n",
    "            ch = ch_names[i]\n",
    "            # Scale and offset each channel for better visualization\n",
    "            scaled_data = data_clean[i] * 1e6  # Convert to µV\n",
    "            offset = i * 50  # Offset for visualization\n",
    "\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=times,\n",
    "                y=scaled_data + offset,\n",
    "                name=ch,\n",
    "                line=dict(width=1)\n",
    "            ))\n",
    "\n",
    "        if identifier in logs and logs[identifier]:\n",
    "            for timestamp, color, description in logs[identifier]:\n",
    "                event_time = timestamp - first_timestamp\n",
    "                if event_time >= 0 and event_time <= times[-1]:\n",
    "                    marker_text = \"\"\n",
    "                    marker_color = color\n",
    "\n",
    "                    if '+' in description:\n",
    "                        marker_text = \"+\"\n",
    "                    elif \"lightblue\" in description.lower():\n",
    "                        marker_text = \"overt\"\n",
    "                    elif \"blue\" in description.lower():\n",
    "                        marker_text = \"covert\"\n",
    "                    try:\n",
    "                        fig.add_vline(\n",
    "                            x=event_time,\n",
    "                            line=dict(color=marker_color, width=1, dash=\"dash\"),\n",
    "                            annotation_text=marker_text,\n",
    "                            annotation_position=\"top right\"\n",
    "                        )\n",
    "                    except ValueError as e:\n",
    "                        print(f\"  - Warning: Could not add marker at {event_time}s: {str(e)}\")\n",
    "                        fig.add_vline(\n",
    "                            x=event_time,\n",
    "                            line=dict(color=\"gray\", width=1, dash=\"dash\"),\n",
    "                            annotation_text=marker_text,\n",
    "                            annotation_position=\"top right\"\n",
    "                        )\n",
    "\n",
    "        fig.update_layout(\n",
    "            title=f\"Clean EEG Data with Event Markers - {os.path.basename(file_path)}\",\n",
    "            xaxis_title=\"Time (s)\",\n",
    "            yaxis_title=\"Amplitude (µV + offset)\",\n",
    "            height=600,\n",
    "            showlegend=True\n",
    "        )\n",
    "\n",
    "        output_file = f\"{results_dir}/{os.path.basename(file_path).replace('.csv', '_processed.html')}\"\n",
    "        fig.write_html(output_file)\n",
    "        print(f\"Interactive visualization saved to: {output_file}\")\n",
    "\n",
    "        print(\"\\nSUMMARY FINDINGS:\")\n",
    "        print(f\"  - Recording duration: {times[-1]:.2f} seconds\")\n",
    "        print(f\"  - Channels analyzed: {len(ch_names)}\")\n",
    "\n",
    "        # Calculate SNR (signal-to-noise ratio) - simplified approach\n",
    "        # Using alpha band power during fixation vs. during word presentation as a proxy\n",
    "        if identifier in logs and logs[identifier]:\n",
    "            try:\n",
    "                cross_periods = []\n",
    "                word_periods = []\n",
    "\n",
    "                for timestamp, _, description in logs[identifier]:\n",
    "                    rel_time = timestamp - first_timestamp\n",
    "                    if rel_time >= 0 and rel_time <= times[-1]:\n",
    "                        time_idx = int(rel_time * sfreq)\n",
    "                        if '+' in description:\n",
    "                            end_idx = min(time_idx + int(sfreq), len(times))\n",
    "                            cross_periods.append((time_idx, end_idx))\n",
    "                        elif 'word' in description.lower() and not 'again' in description.lower():\n",
    "                            end_idx = min(time_idx + int(2 * sfreq), len(times))\n",
    "                            word_periods.append((time_idx, end_idx))\n",
    "\n",
    "                if cross_periods and word_periods:\n",
    "                    alpha_cross = []\n",
    "                    for start, end in cross_periods:\n",
    "                        for ch in range(len(ch_names)):\n",
    "                            # Simple FFT-based power in 8-13 Hz\n",
    "                            if end - start > 0:  # Make sure window has data\n",
    "                                segment = data_clean[ch, start:end]\n",
    "                                fft_vals = np.abs(np.fft.rfft(segment))\n",
    "                                fft_freq = np.fft.rfftfreq(len(segment), 1.0/sfreq)\n",
    "\n",
    "                                # Get alpha band power\n",
    "                                alpha_idx = np.logical_and(fft_freq >= 8, fft_freq <= 13)\n",
    "                                alpha_power = np.mean(fft_vals[alpha_idx]**2)\n",
    "                                alpha_cross.append(alpha_power)\n",
    "\n",
    "                    # Calculate alpha power during word presentation\n",
    "                    alpha_word = []\n",
    "                    for start, end in word_periods:\n",
    "                        for ch in range(len(ch_names)):\n",
    "                            if end - start > 0:  # Make sure window has data\n",
    "                                segment = data_clean[ch, start:end]\n",
    "                                fft_vals = np.abs(np.fft.rfft(segment))\n",
    "                                fft_freq = np.fft.rfftfreq(len(segment), 1.0/sfreq)\n",
    "\n",
    "                                # Get alpha band power\n",
    "                                alpha_idx = np.logical_and(fft_freq >= 8, fft_freq <= 13)\n",
    "                                alpha_power = np.mean(fft_vals[alpha_idx]**2)\n",
    "                                alpha_word.append(alpha_power)\n",
    "\n",
    "                    if alpha_cross and alpha_word:\n",
    "                        alpha_cross_mean = np.mean(alpha_cross)\n",
    "                        alpha_word_mean = np.mean(alpha_word)\n",
    "\n",
    "                        # Calculate alpha ERD (event-related desynchronization)\n",
    "                        alpha_erd_pct = ((alpha_cross_mean - alpha_word_mean) / alpha_cross_mean) * 100\n",
    "\n",
    "                        if alpha_erd_pct > 0:\n",
    "                            print(f\"  - Alpha ERD during word presentation: {alpha_erd_pct:.2f}%\")\n",
    "                            if alpha_erd_pct > 15:\n",
    "                                print(\"    * Strong alpha suppression suggests attentive processing\")\n",
    "                            elif alpha_erd_pct > 5:\n",
    "                                print(\"    * Moderate alpha suppression observed\")\n",
    "                            else:\n",
    "                                print(\"    * Minimal alpha suppression observed\")\n",
    "                        else:\n",
    "                            print(f\"  - Alpha ERS during word presentation: {-alpha_erd_pct:.2f}%\")\n",
    "                            print(\"    * Unusual alpha synchronization - potential artifact or unique task effect\")\n",
    "            except Exception as e:\n",
    "                print(f\"  - Could not calculate alpha ERD/ERS: {str(e)}\")\n",
    "\n",
    "        return {\n",
    "            'success': True,\n",
    "            'file': os.path.basename(file_path),\n",
    "            'channels': len(ch_names),\n",
    "            'samples': len(times),\n",
    "            'duration': times[-1],\n",
    "            'events': len(logs.get(identifier, [])),\n",
    "            'visualization': output_file\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR during processing: {str(e)}\")\n",
    "        traceback.print_exc()\n",
    "        return {\n",
    "            'success': False,\n",
    "            'file': os.path.basename(file_path),\n",
    "            'error': str(e)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scanning data directory...\n",
      "\n",
      "Found 3 valid files to process\n",
      "\n",
      "================================================================================\n",
      "Processing file: Aws Safi1742289648917_EPOCX_211983_2025.03.18T12.20.50+03.00.md.pm.bp.csv\n",
      "================================================================================\n",
      "Successfully read data: 86586 rows, 169 columns\n",
      "Set 'Timestamp' as index\n",
      "Found 14 EEG channels: EEG.AF3, EEG.F7, EEG.F3, EEG.FC5, EEG.T7, EEG.P7, EEG.O1, EEG.O2, EEG.P8, EEG.T8, EEG.FC6, EEG.F4, EEG.F8, EEG.AF4\n",
      "Signal quality analysis:\n",
      "  - Poor quality samples: 0 (0.00%)\n",
      "  - Channels with poorest quality:\n",
      "    * AF3: 0.00% poor quality, avg quality: 4.00\n",
      "    * F7: 0.00% poor quality, avg quality: 4.00\n",
      "    * F3: 0.00% poor quality, avg quality: 4.00\n",
      "Sampling frequency: 128.07 Hz\n",
      "Creating RawArray with float64 data, n_channels=14, n_times=86586\n",
      "    Range : 0 ... 86585 =      0.000 ...   676.053 secs\n",
      "Ready.\n",
      "Successfully set 10-20 montage\n",
      "\n",
      "Applying preprocessing steps:\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 64 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 64.00 Hz\n",
      "- Upper transition bandwidth: 0.04 Hz (-6 dB cutoff frequency: 64.02 Hz)\n",
      "- Filter length: 11383 samples (88.878 s)\n",
      "\n",
      "  - Applied band-pass filter (1-40 Hz)\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.50 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz\n",
      "- Filter length: 847 samples (6.613 s)\n",
      "\n",
      "  - Applied notch filter (50/60 Hz)\n",
      "\n",
      "Spectral analysis:\n",
      "Effective window size : 1.999 (s)\n",
      "psd: <Power Spectrum (from Raw, welch method) | 14 channels × 7 freqs, 0.5-3.5 Hz>\n",
      "psd type: <class 'mne.time_frequency.spectrum.Spectrum'>\n",
      "Effective window size : 1.999 (s)\n",
      "psd: <Power Spectrum (from Raw, welch method) | 14 channels × 8 freqs, 4.0-7.5 Hz>\n",
      "psd type: <class 'mne.time_frequency.spectrum.Spectrum'>\n",
      "Effective window size : 1.999 (s)\n",
      "psd: <Power Spectrum (from Raw, welch method) | 14 channels × 8 freqs, 8.0-11.5 Hz>\n",
      "psd type: <class 'mne.time_frequency.spectrum.Spectrum'>\n",
      "Effective window size : 1.999 (s)\n",
      "psd: <Power Spectrum (from Raw, welch method) | 14 channels × 36 freqs, 12.0-29.5 Hz>\n",
      "psd type: <class 'mne.time_frequency.spectrum.Spectrum'>\n",
      "Effective window size : 1.999 (s)\n",
      "psd: <Power Spectrum (from Raw, welch method) | 14 channels × 68 freqs, 30.0-63.5 Hz>\n",
      "psd type: <class 'mne.time_frequency.spectrum.Spectrum'>\n",
      "  - Delta power: 90.73%\n",
      "  - Theta power: 3.58%\n",
      "  - Alpha power: 5.05%\n",
      "  - Beta power: 0.53%\n",
      "  - Gamma power: 0.12%\n",
      "  - Dominant frequency band: Delta\n",
      "\n",
      "Running ICA for artifact removal:\n",
      "Fitting ICA to data using 14 channels (please be patient, this may take a while)\n",
      "Selecting by number: 14 components\n",
      "Fitting ICA took 0.9s.\n",
      "  - Could not automatically identify eye artifacts: No EOG channel(s) found\n",
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (14 components)\n",
      "    Zeroing out 0 ICA components\n",
      "    Projecting back using 14 PCA components\n",
      "  - Successfully applied ICA correction\n",
      "  - cross: 540 occurrences\n",
      "\n",
      "Generating visualization...\n",
      "Interactive visualization saved to: results/Aws Safi1742289648917_EPOCX_211983_2025.03.18T12.20.50+03.00.md.pm.bp_processed.html\n",
      "\n",
      "SUMMARY FINDINGS:\n",
      "  - Recording duration: 676.05 seconds\n",
      "  - Channels analyzed: 14\n",
      "\n",
      "================================================================================\n",
      "Processing file: Aws Safi1742290353356_EPOCX_211983_2025.03.18T12.32.34+03.00.md.pm.bp.csv\n",
      "================================================================================\n",
      "Successfully read data: 86615 rows, 169 columns\n",
      "Set 'Timestamp' as index\n",
      "Found 14 EEG channels: EEG.AF3, EEG.F7, EEG.F3, EEG.FC5, EEG.T7, EEG.P7, EEG.O1, EEG.O2, EEG.P8, EEG.T8, EEG.FC6, EEG.F4, EEG.F8, EEG.AF4\n",
      "Signal quality analysis:\n",
      "  - Poor quality samples: 0 (0.00%)\n",
      "  - Channels with poorest quality:\n",
      "    * AF3: 0.00% poor quality, avg quality: 4.00\n",
      "    * F7: 0.00% poor quality, avg quality: 4.00\n",
      "    * F3: 0.00% poor quality, avg quality: 4.00\n",
      "Sampling frequency: 128.07 Hz\n",
      "Creating RawArray with float64 data, n_channels=14, n_times=86615\n",
      "    Range : 0 ... 86614 =      0.000 ...   676.280 secs\n",
      "Ready.\n",
      "Successfully set 10-20 montage\n",
      "\n",
      "Applying preprocessing steps:\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 64 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 64.00 Hz\n",
      "- Upper transition bandwidth: 0.04 Hz (-6 dB cutoff frequency: 64.02 Hz)\n",
      "- Filter length: 11383 samples (88.878 s)\n",
      "\n",
      "  - Applied band-pass filter (1-40 Hz)\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.50 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz\n",
      "- Filter length: 847 samples (6.613 s)\n",
      "\n",
      "  - Applied notch filter (50/60 Hz)\n",
      "\n",
      "Spectral analysis:\n",
      "Effective window size : 1.999 (s)\n",
      "psd: <Power Spectrum (from Raw, welch method) | 14 channels × 7 freqs, 0.5-3.5 Hz>\n",
      "psd type: <class 'mne.time_frequency.spectrum.Spectrum'>\n",
      "Effective window size : 1.999 (s)\n",
      "psd: <Power Spectrum (from Raw, welch method) | 14 channels × 8 freqs, 4.0-7.5 Hz>\n",
      "psd type: <class 'mne.time_frequency.spectrum.Spectrum'>\n",
      "Effective window size : 1.999 (s)\n",
      "psd: <Power Spectrum (from Raw, welch method) | 14 channels × 8 freqs, 8.0-11.5 Hz>\n",
      "psd type: <class 'mne.time_frequency.spectrum.Spectrum'>\n",
      "Effective window size : 1.999 (s)\n",
      "psd: <Power Spectrum (from Raw, welch method) | 14 channels × 36 freqs, 12.0-29.5 Hz>\n",
      "psd type: <class 'mne.time_frequency.spectrum.Spectrum'>\n",
      "Effective window size : 1.999 (s)\n",
      "psd: <Power Spectrum (from Raw, welch method) | 14 channels × 68 freqs, 30.0-63.5 Hz>\n",
      "psd type: <class 'mne.time_frequency.spectrum.Spectrum'>\n",
      "  - Delta power: 86.15%\n",
      "  - Theta power: 5.69%\n",
      "  - Alpha power: 7.50%\n",
      "  - Beta power: 0.56%\n",
      "  - Gamma power: 0.10%\n",
      "  - Dominant frequency band: Delta\n",
      "\n",
      "Running ICA for artifact removal:\n",
      "Fitting ICA to data using 14 channels (please be patient, this may take a while)\n",
      "Selecting by number: 14 components\n",
      "Fitting ICA took 0.7s.\n",
      "  - Could not automatically identify eye artifacts: No EOG channel(s) found\n",
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (14 components)\n",
      "    Zeroing out 0 ICA components\n",
      "    Projecting back using 14 PCA components\n",
      "  - Successfully applied ICA correction\n",
      "  - cross: 540 occurrences\n",
      "\n",
      "Generating visualization...\n",
      "Interactive visualization saved to: results/Aws Safi1742290353356_EPOCX_211983_2025.03.18T12.32.34+03.00.md.pm.bp_processed.html\n",
      "\n",
      "SUMMARY FINDINGS:\n",
      "  - Recording duration: 676.28 seconds\n",
      "  - Channels analyzed: 14\n",
      "\n",
      "================================================================================\n",
      "Processing file: Aws Safi1742291163364_EPOCX_211983_2025.03.18T12.46.04+03.00.md.pm.bp.csv\n",
      "================================================================================\n",
      "Successfully read data: 86582 rows, 169 columns\n",
      "Set 'Timestamp' as index\n",
      "Found 14 EEG channels: EEG.AF3, EEG.F7, EEG.F3, EEG.FC5, EEG.T7, EEG.P7, EEG.O1, EEG.O2, EEG.P8, EEG.T8, EEG.FC6, EEG.F4, EEG.F8, EEG.AF4\n",
      "Signal quality analysis:\n",
      "  - Poor quality samples: 0 (0.00%)\n",
      "  - Channels with poorest quality:\n",
      "    * AF3: 0.00% poor quality, avg quality: 4.00\n",
      "    * F7: 0.00% poor quality, avg quality: 4.00\n",
      "    * F3: 0.00% poor quality, avg quality: 2.68\n",
      "Sampling frequency: 128.07 Hz\n",
      "Creating RawArray with float64 data, n_channels=14, n_times=86582\n",
      "    Range : 0 ... 86581 =      0.000 ...   676.022 secs\n",
      "Ready.\n",
      "Successfully set 10-20 montage\n",
      "\n",
      "Applying preprocessing steps:\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 64 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.50\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
      "- Upper passband edge: 64.00 Hz\n",
      "- Upper transition bandwidth: 0.04 Hz (-6 dB cutoff frequency: 64.02 Hz)\n",
      "- Filter length: 11383 samples (88.878 s)\n",
      "\n",
      "  - Applied band-pass filter (1-40 Hz)\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower transition bandwidth: 0.50 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz\n",
      "- Filter length: 847 samples (6.613 s)\n",
      "\n",
      "  - Applied notch filter (50/60 Hz)\n",
      "\n",
      "Spectral analysis:\n",
      "Effective window size : 1.999 (s)\n",
      "psd: <Power Spectrum (from Raw, welch method) | 14 channels × 7 freqs, 0.5-3.5 Hz>\n",
      "psd type: <class 'mne.time_frequency.spectrum.Spectrum'>\n",
      "Effective window size : 1.999 (s)\n",
      "psd: <Power Spectrum (from Raw, welch method) | 14 channels × 8 freqs, 4.0-7.5 Hz>\n",
      "psd type: <class 'mne.time_frequency.spectrum.Spectrum'>\n",
      "Effective window size : 1.999 (s)\n",
      "psd: <Power Spectrum (from Raw, welch method) | 14 channels × 8 freqs, 8.0-11.5 Hz>\n",
      "psd type: <class 'mne.time_frequency.spectrum.Spectrum'>\n",
      "Effective window size : 1.999 (s)\n",
      "psd: <Power Spectrum (from Raw, welch method) | 14 channels × 36 freqs, 12.0-29.5 Hz>\n",
      "psd type: <class 'mne.time_frequency.spectrum.Spectrum'>\n",
      "Effective window size : 1.999 (s)\n",
      "psd: <Power Spectrum (from Raw, welch method) | 14 channels × 68 freqs, 30.0-63.5 Hz>\n",
      "psd type: <class 'mne.time_frequency.spectrum.Spectrum'>\n",
      "  - Delta power: 85.97%\n",
      "  - Theta power: 4.69%\n",
      "  - Alpha power: 8.52%\n",
      "  - Beta power: 0.68%\n",
      "  - Gamma power: 0.13%\n",
      "  - Dominant frequency band: Delta\n",
      "\n",
      "Running ICA for artifact removal:\n",
      "Fitting ICA to data using 14 channels (please be patient, this may take a while)\n",
      "Selecting by number: 14 components\n",
      "Fitting ICA took 0.6s.\n",
      "  - Could not automatically identify eye artifacts: No EOG channel(s) found\n",
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (14 components)\n",
      "    Zeroing out 0 ICA components\n",
      "    Projecting back using 14 PCA components\n",
      "  - Successfully applied ICA correction\n",
      "  - cross: 540 occurrences\n",
      "\n",
      "Generating visualization...\n",
      "Interactive visualization saved to: results/Aws Safi1742291163364_EPOCX_211983_2025.03.18T12.46.04+03.00.md.pm.bp_processed.html\n",
      "\n",
      "SUMMARY FINDINGS:\n",
      "  - Recording duration: 676.02 seconds\n",
      "  - Channels analyzed: 14\n",
      "\n",
      "================================================================================\n",
      "FINAL PROCESSING SUMMARY\n",
      "================================================================================\n",
      "Total files processed: 3\n",
      "Successfully processed: 3\n",
      "Failed processing: 0\n",
      "\n",
      "Successfully processed files:\n",
      "1. Aws Safi1742289648917_EPOCX_211983_2025.03.18T12.20.50+03.00.md.pm.bp.csv - 14 channels, 676.05s, 800 events\n",
      "2. Aws Safi1742290353356_EPOCX_211983_2025.03.18T12.32.34+03.00.md.pm.bp.csv - 14 channels, 676.28s, 800 events\n",
      "3. Aws Safi1742291163364_EPOCX_211983_2025.03.18T12.46.04+03.00.md.pm.bp.csv - 14 channels, 676.02s, 800 events\n",
      "\n",
      "All results saved to: results\n",
      "Complete!\n"
     ]
    }
   ],
   "source": [
    "name = 'Aws Safi'\n",
    "print(\"\\nScanning data directory...\")\n",
    "files_to_process = []\n",
    "\n",
    "for s in os.listdir(data_path):\n",
    "    if not s.endswith('.csv'):\n",
    "        continue\n",
    "    if not s.startswith(name):\n",
    "        continue\n",
    "\n",
    "    identifier = s.split(name)[1].split(\"_\")[0]\n",
    "    file_path = f\"{data_path}/{s}\"\n",
    "\n",
    "    is_valid, message = validate_csv(file_path)\n",
    "    if is_valid:\n",
    "        files_to_process.append((file_path, identifier))\n",
    "    else:\n",
    "        print(f\"Skipping invalid file {s}: {message}\")\n",
    "\n",
    "print(f\"\\nFound {len(files_to_process)} valid files to process\")\n",
    "\n",
    "results = []\n",
    "for file_path, identifier in files_to_process:\n",
    "    if identifier in logs:\n",
    "        result = preprocess_eeg(file_path, identifier, logs)\n",
    "        if result:\n",
    "            results.append(result)\n",
    "    else:\n",
    "        print(f\"Skipping {file_path} - no matching log file found\")\n",
    "\n",
    "successful = [r for r in results if r.get('success', False)]\n",
    "failed = [r for r in results if not r.get('success', False)]\n",
    "\n",
    "print(f\"\\n{'='*80}\\nFINAL PROCESSING SUMMARY\\n{'='*80}\")\n",
    "print(f\"Total files processed: {len(results)}\")\n",
    "print(f\"Successfully processed: {len(successful)}\")\n",
    "print(f\"Failed processing: {len(failed)}\")\n",
    "\n",
    "if successful:\n",
    "    print(\"\\nSuccessfully processed files:\")\n",
    "    for i, result in enumerate(successful, 1):\n",
    "        print(f\"{i}. {result['file']} - {result['channels']} channels, {result['duration']:.2f}s, {result['events']} events\")\n",
    "\n",
    "if failed:\n",
    "    print(\"\\nFailed files:\")\n",
    "    for i, result in enumerate(failed, 1):\n",
    "        print(f\"{i}. {result['file']} - Error: {result['error']}\")\n",
    "\n",
    "print(f\"\\nAll results saved to: {results_dir}\")\n",
    "print(\"Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1742291164.418252"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"data/Aws Safi1742291163364_EPOCX_211983_2025.03.18T12.46.04+03.00.md.pm.bp.csv\")['OriginalTimestamp'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2025-03-18T12:46:04.525Z'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = '2025-03-18T09:46:04.525Z'.split('T')\n",
    "k[1]= str(int(k[1][:2])+3)+k[1][2:]\n",
    "'T'.join(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unix Timestamp: 1742291164.418252\n",
      "ISO Format (UTC): 2025-03-18T09:46:04.418Z\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "unix_timestamp = 1742291164.418252\n",
    "\n",
    "dt_object_utc = datetime.datetime.utcfromtimestamp(unix_timestamp)\n",
    "iso_format_string = dt_object_utc.isoformat(timespec='milliseconds') + 'Z'\n",
    "\n",
    "print(f\"Unix Timestamp: {unix_timestamp}\")\n",
    "print(f\"ISO Format (UTC): {iso_format_string}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
